{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test other backbones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.unet import Unet\n",
    "from model.backbone import BackboneOriginal, BackBoneResnet101, BackBoneResnet18\n",
    "net = Unet(BackBoneResnet18, encoder_args = {\"pretrained\":False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 512, 512])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.empty((1, 1, 512, 512))\n",
    "net(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "len(nn.Sequential(nn.Conv2d(1, 1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.backbone import BackBoneResnet101\n",
    "backbone = BackBoneResnet101(encoder_args = {}, decoder_args = {})\n",
    "# backbone.blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet101\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch\n",
    "writer = SummaryWriter(\"tensorboard_resnet101\")\n",
    "x = torch.empty((1, 3, 256, 256))\n",
    "# x = torch.cat([x,x,x], dim = 1)\n",
    "writer.add_graph(resnet101(), x)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 3 required positional arguments: 'current_epoch', 'epochs', and 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-91d15fd4c42b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvisualize\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mVisualize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mvis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVisualize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 3 required positional arguments: 'current_epoch', 'epochs', and 'data'"
     ]
    }
   ],
   "source": [
    "from visualize.visualize import Visualize\n",
    "vis = Visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# vis.plot_loss_update(0.1, 0.5)\n",
    "image = plt.imread(\"E:\\data\\BrainTumor\\masks\\\\7_1.jpg\")\n",
    "# vis.update_image(image[:,:,0])\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test SegmentationData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.SegmentationData import SegmentationData\n",
    "from config import config\n",
    "data = SegmentationData(config)\n",
    "# data.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.SegmentationData import SegmentationData\n",
    "from config import config\n",
    "from train.train import Trainer\n",
    "import torch\n",
    "data = SegmentationData(config)\n",
    "trainer = Trainer(config, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampler = trainer.data.load_batch(\"train\")\n",
    "# images = sampler[0][0:1].to(trainer.device)\n",
    "# labels = sampler[1][0:1].to(trainer.device)\n",
    "# trainer.net.eval()\n",
    "# with torch.no_grad():\n",
    "#     outputs = trainer.net(images)\n",
    "#     outputs_sigmoid = torch.sigmoid(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/10 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='536' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/536 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6984)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.crition(labels, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.SegmentationData import SegmentationData\n",
    "from config import config\n",
    "data = SegmentationData(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.Unet import Unet\n",
    "import torch\n",
    "x = torch.ones([1, 1, 192, 192])\n",
    "net = Unet(1, 1, padding = 1)\n",
    "x.shape, net(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.Unet import Up\n",
    "import torch\n",
    "x = torch.empty([1, 1024, 4, 4])\n",
    "up = Up([1024, 512, 512])\n",
    "up(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from model.Unet import MultiConv\n",
    "MultiConv([2, 1, 1], True, 0)(x1)\n",
    "\n",
    "nn.BatchNorm2d(1)(x2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "diffY = x2.size()[2] - x1.size()[2]\n",
    "diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "x2 = F.pad(x2, [\n",
    "        -diffX//2, -diffX//2,\n",
    "        -diffY//2, -diffY//2\n",
    "        ])\n",
    "x1.shape, x2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test BrainTumorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.BrainTumorDataset import BrainTumorDataset\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(256),\n",
    "    transforms.ToTensor()\n",
    "]\n",
    ")\n",
    "dataset_args = {\n",
    "    \"input_folder\":'E:\\data\\BrainTumor',\n",
    "}\n",
    "dataset = BrainTumorDataset(dataset_args, transform_train, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.show_sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test split train val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.BrainTumorDataset import PrepairBrainTumorDataset\n",
    "prepaireDataset = PrepairBrainTumorDataset('E:\\data\\BrainTumorRaw','E:\\data\\BrainTumor')\n",
    "prepaireDataset.split_train_test_val()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
